{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDOWM_QYlbUR"
      },
      "source": [
        "## Clustering\n",
        "* Is an example of descriptive analytics or unsupervised learning\n",
        "* We are extracting information from unlabeled data\n",
        "* Clustering is concerned with grouping together objects that are similar to each other and dissimilar to the objects belonging to other clusters.\n",
        "* Interpretation of the resultst might be difficult.\n",
        "* Many business fields can benefit from Clustering techniques: \n",
        "    * In an economics application we might be interested in finding countries whose economies are similar.\n",
        "    * In a financial application we might wish to find clusters of companies that have similar financial performance.\n",
        "    * In a marketing application we might wish to find clusters of customers with similar buying behavior (= Customer segmentation)\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9J53Af_lbUT"
      },
      "source": [
        "### Example of customer segmentation\n",
        "<center><img src=\"https://github.com/HOGENT-Databases/BI-BigData/blob/master/notebooks/images/clusters.png?raw=1\"></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YOraF_HlbUU"
      },
      "source": [
        "### Clustering basics\n",
        "**Centroid** of cluster = point for which each attribute value is the average of the values of the corresponding attribute for all the points in the cluster. Example: the centroid of the four points (with 6 attributes)\n",
        "\n",
        "| 1 |2 | 3 | 4 | 5 | 6 |\n",
        "| :---: | :---: | :---: | :----: | :----: | :----: |\n",
        "| 8.0 | 7.2 | 0.3 | 23.1 | 11.1 | -6.1 |\n",
        "| 2.0 | -3.4 | 0.8 | 24.2 | 18.3 | -5.2 |\n",
        "| -3.5 | 8.1 | 0.9 | 20.6 | 10.2 | -7.3 |\n",
        "| -6.0 | 6.7 | 0.5 | 12.5 | 9.2 | -8.4 |  \n",
        "  \n",
        "would be:  \n",
        "\n",
        "| 1 | 2 | 3 | 4 | 5 | 6 |\n",
        "| :---: | :---: | :---: | :----: | :----: | :----: |\n",
        "| 0.125 | 4.65 | 0.625 | 20.1 | 12.2 | -6.75 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0qfT1zzlbUU"
      },
      "source": [
        "### Clustering methods available in Python\n",
        "<center><img src=\"https://github.com/HOGENT-Databases/BI-BigData/blob/master/notebooks/images/clustering_in_python_table.png?raw=1\"></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wc4-maJJlbUU"
      },
      "source": [
        "### k-means Clustering\n",
        "* Exclusive clustering algorithm: each object is assigned to precisely one of a set of clusters.\n",
        "* Start by deciding how many clusters we would like to form from our data &rarr; k\n",
        "* There are many ways in which k clusters might potentially be formed.\n",
        "* We measure the quality of a set of clusters by calculating the sum of the squares of the distances of each point from the centroid of the cluster to which it is assigned:   \n",
        "  \n",
        "    **`wcss = within cluster sum of squares`**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMW3ILgslbUV"
      },
      "source": [
        "### k-means Clustering\n",
        "* Select k observations as initial cluster centroids (seeds)\n",
        "* Assign each observation to cluster that has closest centroid (for example, in Euclidean sense)\n",
        "* When all observations have been assigned, recalculate positions of K centroids\n",
        "* Repeat until cluster centroids no longer change"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVsC_o60lbUV"
      },
      "source": [
        "### k-means Clustering\n",
        "<center><img src=\"https://github.com/HOGENT-Databases/BI-BigData/blob/master/notebooks/images/kmeans.png?raw=1\"></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kroc9DcMlbUW"
      },
      "source": [
        "### Clustering: distance measures\n",
        "<center><img src=\"https://github.com/HOGENT-Databases/BI-BigData/blob/master/notebooks/images/distance.jpg?raw=1\"></center>  \n",
        "  \n",
        "  \n",
        "<center><img src=\"https://github.com/HOGENT-Databases/BI-BigData/blob/master/notebooks/images/distance_formulas.png?raw=1\"></center>  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20g8fJMilbUW"
      },
      "source": [
        "### k-means: example\n",
        "We will illustrate the k-means algorithm by using it to cluster the 16 objects with two attributes x and y."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZifG1DkglbUW"
      },
      "source": [
        "<center><img src=\"https://github.com/HOGENT-Databases/BI-BigData/blob/master/notebooks/images/kmeans_example.png?raw=1\"></center>  \n",
        "The 16 points corresponding to these objects are shown in this diagram (x = horizontal axis, y = vertical-axis).   \n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvxCweKalbUX"
      },
      "source": [
        "We choose k = 3 and arbitrarily 3 initial centroids. \n",
        "<center><img src=\"https://github.com/HOGENT-Databases/BI-BigData/blob/master/notebooks/images/kmeans_example1.png?raw=1\"></center>   \n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jwtl7pRklbUX"
      },
      "source": [
        "We then calculate the Euclidean distance for each point to each centroid and assign it to the cluster with the nearest centroid, so we obtain following initial clusters:\n",
        "<center><img src=\"https://github.com/HOGENT-Databases/BI-BigData/blob/master/notebooks/images/kmeans_example2.png?raw=1\"></center>  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Y0-v7a9lbUX"
      },
      "source": [
        "We calculate the centroid of the 3 clusters and reassign the 16 points to the clusters. The centroids are now imaginary points. One point has moved: (8.4,6.9) from cluster 2 to cluster 1\n",
        "<center><img src=\"https://github.com/HOGENT-Databases/BI-BigData/blob/master/notebooks/images/kmeans_example3.png?raw=1\"></center>  \n",
        "We recalculate the centroids again and reassign the points. We repeat this process until no more points move and the iteration stops. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abmGSHZclbUX"
      },
      "source": [
        "### k-means: optimal number of clusters\n",
        "* Note that we are not trying to find the value of k with the smallest value of wcss. \n",
        "* That will occur when the value of k is the same as the number of objects, i.e. each object forms its own cluster of one.\n",
        "* wcss will then be zero, but the clusters will be worthless. \n",
        "* This is another example of overfitting. \n",
        "  \n",
        "We can use the elbow method to find the optimal number of clusters. \n",
        "<center><img src=\"https://github.com/HOGENT-Databases/BI-BigData/blob/master/notebooks/images/kmeans_elbow.png?raw=1\"></center>  "
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "clustering.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}